{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KgHS3-dzhSpf"
   },
   "source": [
    "## Numbers for use in dataset essay\n",
    "\n",
    "Collect totals and other numbers and output as LaTeX variables, for use in the dataset essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils import pgp_csv_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents & Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv(pgp_csv_paths[\"documents\"])\n",
    "total_documents = documents.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_fragments = documents.copy()\n",
    "documents_fragments[\"fragments\"] = documents_fragments.shelfmark.apply(lambda x : x.split(' + '))\n",
    "documents_fragments[\"num_fragments\"] = documents_fragments.fragments.apply(lambda x : len(x))\n",
    "single_frag_docs = documents_fragments[documents_fragments.num_fragments == 1].shape[0]\n",
    "joins = documents_fragments[documents_fragments.num_fragments > 1].shape[0]\n",
    "\n",
    "essay_numbers = {\n",
    "    \"totalDocuments\": f\"{total_documents:,}\",\n",
    "    \"singleFragmentDocuments\": f\"{single_frag_docs:,}\",\n",
    "    \"totalJoins\": f\"{joins:,}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# copy dataframe and replace unset type with \"Unknown\" so we can include it in reported type totals\n",
    "docs_with_unknowns = documents.copy()\n",
    "docs_with_unknowns[\"type\"] = docs_with_unknowns.type.fillna(\"Unknown\")\n",
    "doctype_totals = docs_with_unknowns.type.value_counts()\n",
    "\n",
    "def texOutputLabel(term):\n",
    "  # convert a variable name or string into format for tex variable output\n",
    "  # remove numbers and dashes\n",
    "  term = re.sub(r'[-\\d]', '', term)\n",
    "  # remove spaces, and use title/camel case\n",
    "  return ''.join([t.title() for t in term.split()])\n",
    "\n",
    "for doctype, total in doctype_totals.to_dict().items():\n",
    "  # add to output numbers for essay; prefix with total and convert for output\n",
    "  outputLabel = f\"total{texOutputLabel(doctype)}\"\n",
    "  essay_numbers[outputLabel] = f\"{total:,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['tag_list'] = documents.tags.apply(lambda x: x.strip().split(\", \") if pd.notna(x) else [])\n",
    "docs_tags = documents[['pgpid', 'tag_list']].explode('tag_list').rename(columns={'tag_list': 'tag'})\n",
    "# filter out unset tags\n",
    "docs_tags = docs_tags[docs_tags.tag.notna()]\n",
    "essay_numbers['uniqueTags'] = f\"{len(docs_tags.tag.unique()):,}\"\n",
    "\n",
    "tag_counts = docs_tags.tag.value_counts().reset_index()\n",
    "\n",
    "# add top 7 most common tags to output numbers for inclusion in essay\n",
    "for tagcount in tag_counts.head(6).itertuples():\n",
    "  essay_numbers[f'tagged{texOutputLabel(tagcount.tag)}'] = tagcount.count\n",
    "\n",
    "singletons = tag_counts[tag_counts[\"count\"] == 1]\n",
    "essay_numbers['singletonTags'] = f\"{singletons.shape[0]:,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine primary and secondary languages into an all-lang field\n",
    "\n",
    "def all_langs(row):\n",
    "  # apparently we can't assume that secondary lang implies primary!\n",
    "    if pd.notna(row.languages_primary):\n",
    "      if pd.notna(row.languages_secondary):\n",
    "        return ','.join([row.languages_primary, row.languages_secondary])\n",
    "      else:\n",
    "        return row.languages_primary\n",
    "\n",
    "    # at least one case has a secondary lang without primary; return it\n",
    "    if pd.notna(row.languages_secondary):\n",
    "      return row.languages_secondary\n",
    "\n",
    "\n",
    "documents['languages_all'] = documents.apply(all_langs, axis=1)\n",
    "\n",
    "# split and explode the combined languages into list\n",
    "documents['langs_all_list'] = documents.languages_all.apply(lambda x: (x.strip().split(\",\")) if pd.notna(x) else [])\n",
    "\n",
    "docs_langs = documents[['pgpid', 'langs_all_list']].explode('langs_all_list').rename(columns={\"langs_all_list\": \"language\"})\n",
    "# filter out unset languages\n",
    "docs_langs = docs_langs[docs_langs.language.notna()]\n",
    "# ensure whitespace doesn't cause variation\n",
    "docs_langs['language'] = docs_langs.language.apply(lambda x : x.strip())\n",
    "\n",
    "doc_lang_counts = docs_langs.language.value_counts().reset_index()\n",
    "\n",
    "total_langs = len(doc_lang_counts.language.unique())\n",
    "\n",
    "# tally the number of languages using the combined list field we created before\n",
    "documents['langs_all_count'] = documents.langs_all_list.apply(lambda x: len(x))\n",
    "\n",
    "docs_no_lang = documents[documents['langs_all_count'] == 0].shape[0]\n",
    "docs_any_lang = documents[documents['langs_all_count'] != 0].shape[0]\n",
    "docs_one_lang = documents[documents['langs_all_count'] == 1].shape[0]\n",
    "docs_multi_lang = documents[documents['langs_all_count'] > 1].shape[0]\n",
    "\n",
    "essay_numbers.update({\n",
    "    'totalLangauges': f\"{len(doc_lang_counts.language.unique()):,}\",\n",
    "    'documentsNoLang': f\"{docs_no_lang:,}\",\n",
    "    'documentsAnyLang': f\"{docs_any_lang:,}\",\n",
    "    'documentsOneLang': f\"{docs_one_lang:,}\",\n",
    "    'documentsMultiLang': f\"{docs_multi_lang:,}\",\n",
    "    # what % of documents with any language are multi/mono lingual?\n",
    "    'percentDocsMultiLang': f\"{docs_multi_lang/docs_any_lang:.1%}\",\n",
    "    'percentDocsMonoLang': f\"{docs_one_lang/docs_any_lang:.1%}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to documents with standard date OR inferred date information\n",
    "dated_docs = documents[documents.doc_date_standard.notna() | documents.inferred_date_standard.notna()].copy()\n",
    "\n",
    "# collect dates into a single field\n",
    "dated_docs['date'] = dated_docs.apply(lambda x: x.doc_date_standard.strip() if pd.notna(x.doc_date_standard) else x.inferred_date_standard.strip(), axis=1)\n",
    "\n",
    "\n",
    "total_docs_anydate = dated_docs[dated_docs.date.notna()].shape[0]\n",
    "total_date_on_doc = dated_docs[dated_docs.doc_date_standard.notna()].shape[0]\n",
    "# inferred date only (don't recount date on doc)\n",
    "total_inferred_date = dated_docs[dated_docs.doc_date_standard.isna() & dated_docs.inferred_date_standard.notna()].shape[0]\n",
    "essay_numbers.update({\n",
    "    'totalDatedDocs': f\"{total_docs_anydate:,}\",\n",
    "    'percentDatedDocs': f\"{total_docs_anydate / total_documents:.1%}\",\n",
    "    'totalDateOnDoc': f\"{total_date_on_doc:,}\",\n",
    "    'totalInferredDate': f\"{total_inferred_date:,}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalDocuments': '35,194',\n",
       " 'singleFragmentDocuments': '33,644',\n",
       " 'totalJoins': '1,550',\n",
       " 'totalLetter': '11,212',\n",
       " 'totalLegalDocument': '7,868',\n",
       " 'totalListOrTable': '5,415',\n",
       " 'totalUnknown': '4,175',\n",
       " 'totalLiteraryText': '2,338',\n",
       " 'totalStateDocument': '2,096',\n",
       " 'totalParaliteraryText': '1,130',\n",
       " 'totalCreditInstrumentOrPrivateReceipt': '554',\n",
       " 'totalLegalQueryOrResponsum': '401',\n",
       " 'totalInscription': '5',\n",
       " 'uniqueTags': '2,674',\n",
       " 'taggedDimme': 1640,\n",
       " 'taggedAccount': 759,\n",
       " 'taggedCommunal': 751,\n",
       " 'taggedIllness': 691,\n",
       " 'taggedIllnessLetter': 648,\n",
       " 'taggedArabicScript': 629,\n",
       " 'singletonTags': '1,064',\n",
       " 'totalLangauges': '54',\n",
       " 'documentsNoLang': '6,161',\n",
       " 'documentsAnyLang': '29,033',\n",
       " 'documentsOneLang': '22,443',\n",
       " 'documentsMultiLang': '6,590',\n",
       " 'percentDocsMultiLang': '22.7%',\n",
       " 'percentDocsMonoLang': '77.3%',\n",
       " 'totalDatedDocs': '4,455',\n",
       " 'percentDatedDocs': '12.7%',\n",
       " 'totalDateOnDoc': '4,127',\n",
       " 'totalInferredDate': '328'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People & Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records in people & places data files?\n",
    "\n",
    "essay_numbers[\"totalPeopleRecords\"] = pd.read_csv(pgp_csv_paths['people']).shape[0]\n",
    "essay_numbers[\"totalPlaceRecords\"] = pd.read_csv(pgp_csv_paths['places']).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AJF_G6KJhXmU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'totalDocuments': '35,194',\n",
       " 'singleFragmentDocuments': '33,644',\n",
       " 'totalJoins': '1,550',\n",
       " 'totalLetter': '11,212',\n",
       " 'totalLegalDocument': '7,868',\n",
       " 'totalListOrTable': '5,415',\n",
       " 'totalUnknown': '4,175',\n",
       " 'totalLiteraryText': '2,338',\n",
       " 'totalStateDocument': '2,096',\n",
       " 'totalParaliteraryText': '1,130',\n",
       " 'totalCreditInstrumentOrPrivateReceipt': '554',\n",
       " 'totalLegalQueryOrResponsum': '401',\n",
       " 'totalInscription': '5',\n",
       " 'uniqueTags': '2,674',\n",
       " 'taggedDimme': 1640,\n",
       " 'taggedAccount': 759,\n",
       " 'taggedCommunal': 751,\n",
       " 'taggedIllness': 691,\n",
       " 'taggedIllnessLetter': 648,\n",
       " 'taggedArabicScript': 629,\n",
       " 'singletonTags': '1,064',\n",
       " 'totalLangauges': '54',\n",
       " 'documentsNoLang': '6,161',\n",
       " 'documentsAnyLang': '29,033',\n",
       " 'documentsOneLang': '22,443',\n",
       " 'documentsMultiLang': '6,590',\n",
       " 'percentDocsMultiLang': '22.7%',\n",
       " 'percentDocsMonoLang': '77.3%',\n",
       " 'totalDatedDocs': '4,455',\n",
       " 'percentDatedDocs': '12.7%',\n",
       " 'totalDateOnDoc': '4,127',\n",
       " 'totalInferredDate': '328',\n",
       " 'totalPeopleRecords': 1333,\n",
       " 'totalPlaceRecords': 409}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output as LaTeX variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dDvZ893lhVTX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% numbers from data\n",
      "\\def\\totalDocuments{35,194}\n",
      "\\def\\singleFragmentDocuments{33,644}\n",
      "\\def\\totalJoins{1,550}\n",
      "\\def\\totalLetter{11,212}\n",
      "\\def\\totalLegalDocument{7,868}\n",
      "\\def\\totalListOrTable{5,415}\n",
      "\\def\\totalUnknown{4,175}\n",
      "\\def\\totalLiteraryText{2,338}\n",
      "\\def\\totalStateDocument{2,096}\n",
      "\\def\\totalParaliteraryText{1,130}\n",
      "\\def\\totalCreditInstrumentOrPrivateReceipt{554}\n",
      "\\def\\totalLegalQueryOrResponsum{401}\n",
      "\\def\\totalInscription{5}\n",
      "\\def\\uniqueTags{2,674}\n",
      "\\def\\taggedDimme{1640}\n",
      "\\def\\taggedAccount{759}\n",
      "\\def\\taggedCommunal{751}\n",
      "\\def\\taggedIllness{691}\n",
      "\\def\\taggedIllnessLetter{648}\n",
      "\\def\\taggedArabicScript{629}\n",
      "\\def\\singletonTags{1,064}\n",
      "\\def\\totalLangauges{54}\n",
      "\\def\\documentsNoLang{6,161}\n",
      "\\def\\documentsAnyLang{29,033}\n",
      "\\def\\documentsOneLang{22,443}\n",
      "\\def\\documentsMultiLang{6,590}\n",
      "\\def\\percentDocsMultiLang{22.7\\%}\n",
      "\\def\\percentDocsMonoLang{77.3\\%}\n",
      "\\def\\totalDatedDocs{4,455}\n",
      "\\def\\percentDatedDocs{12.7\\%}\n",
      "\\def\\totalDateOnDoc{4,127}\n",
      "\\def\\totalInferredDate{328}\n",
      "\\def\\totalPeopleRecords{1333}\n",
      "\\def\\totalPlaceRecords{409}\n"
     ]
    }
   ],
   "source": [
    "# output numbers for the essay as LaTeX defines so they can be referenced in-text\n",
    "\n",
    "def numbers_to_latex(essay_numbers):\n",
    "    # output numbers for the essay as LaTeX defines so they can be referenced in-text\n",
    "    result = []\n",
    "    result.append(\"%% numbers from data\")\n",
    "    for name, value in essay_numbers.items():\n",
    "        # ... or don't [add a space since latex seems to swallow the following space in paragraph text]\n",
    "        # escape special chars in the output\n",
    "        result.append(r\"\\def\\%s{%s}\" % (name, str(value).replace(\"%\", r\"\\%\")))\n",
    "    return \"\\n\".join(result)\n",
    "    \n",
    "print(numbers_to_latex(essay_numbers))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
